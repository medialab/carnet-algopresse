

## Comment sont exprimés les troubles produits par les agents calculateurs

**Visualisation Verbes troubles**

Une autre manière de poursuivre cette analyse comparative des troubles et formes d’agentivité associés aux calculateurs consiste en l’exploration d’une autre entité sémantique au sein du corpus d’articles que sont les verbes mais absente du réseau du fait de la procédure d’extraction. Après avoir réalisé une extraction d’une liste de verbes interprétables  comme étant potentiellement de bons candidats aux troubles produits par les dispositifs techniques, nous avons calculé et comparé leur score tf-idf  au sein des deux sous-ensemble d’articles constitutifs du réseau.
Les verbes dont les scores tf-idf sont les plus importants dans les articles qui composent l’espace sémantique “Robots” viennent conforter l’analyse des troubles effectuée à partir des termes catégorisés comme “Issues” au sein du graphe. En effet, on observe une plus forte représentation de verbes exprimant une menace de la part des machines et intelligences autonomes relevant d’un discours prophétique, voire apocalyptique. Parmi les verbes sélectionnés comme bons candidats à l’expression de troubles ayant les plus importants  scores, on trouve des verbes qui expriment des notions de destruction (doom, destroy, eradicate, kill, eliminate) et de domination des machines sur l'homme (enslave, dominate), mais également de  dépassement ou de remplacement des hommes par les ces agents techniques (overtake, surpass, replace, defeat). D’autres verbes davantage représentés dans le sous ensemble “robots” renvoient à des notions de transformation et de changement  (reshape, transform, disrupt) ou aux capacités de ces agents techniques à imiter ou simuler les comportements humains (ressemble, simulate, reproduce, mimic).
Dans le sous-ensemble d’articles associés aux "Algorithmes" on retrouve également des verbes qui viennent conforter les analyses précédentes réalisées à partir de la catégories “Issues”. En effet, les verbes qui présentent les plus hauts scores de tf-idf renvoient aux questions de filtrage et de censure de l’information (filter, delete, supress, censor), aux problèmes de surveillance et de privacy (profile, suspect, spy, target, track), à la dénoncitation des formes de discrimination (bias, discriminate) ou encore aux phénomènes de propagation et d’amplification de contenus frauduleux (promote, amplify, spread). 


## Comment est exprimée la temporalité ? 

**Visualisation Temporalité**

L'opposition entre les deux espaces sémantiques semble donc dessiner deux régimes d’énonciation distincts qui cohabitent au sein de l’espace médiatique. Le premier exprime les peurs face à des technologies autonomes focalisant la critique sur leur capacité à simuler, dépasser, remplacer ou exterminer à terme l’espèce humaine et représentant une menace qu’il serait nécessaire de contrôler. L’autre régime est davantage ancré dans le répertoire habituel de la critique sociale, mobilisant le répertoire du droit et des  injustices  (censure, discrimination, surveillance) envers des poulations spécifiques ou relève d’enjeux de régulation quant à la manière de gérer la diffusion de l’information (exposition, amplification).

Cette distinction entre l’énonciation de la peur et de la critique s’exprime également à travers les marqueurs temporels. L’espace intitulé “Robots” évoque majoritairement un ensemble de technologies encore en cours de développement au sein de laboratoires de recherche ou de start-ups qui les destinent à des applications dans des domaines très spécialisés, le monde du travail “job automation”, la défense pour les “Killer Robots”, les marchés financiers pour les "Robo-advisors", la sexualité “Sex Robots”. On trouve aussi dans cette partie du graphe les clusters “Scientific research” et ”Future of AI” qui portent tous deux sur des recherches plus fondamentales en lien avec les déploiements les plus récents en intelligence artificielle et en robotisation. L’autre partie du graphe intitulée "Algorithmes" se concentre davantage sur des systèmes techniques largement déployés dans l’environnement technologique quotidien et adoptées par les utilisateurs, tels que les algorithmes du Web, l’automatisation des emails, les algorithmes de moteurs de recherche d’image ou encore la synthèse vocale. Dans cet espace sémantique d’autres technologies commencent à se diffuser auprès du grand public tels que les assistants vocaux, les “Deepfake” via des applications mobiles telles que Reface ou Faceswap. Enfin d’autres dispositifs ne sont pas encore démocratisés mais font pour la plupart l’objet d’expérimentation plus ou moins importantes par des institutions et des sociétés tels que la reconnaissance faciale, les algorithmes prédictifs dans le domaine de la police et de la justice par exemple qui connaissent actuellement des développement locaux, à l’échelle d’une institution ou d’un territoire, tout en faisant l’objet d’une attention particulière en terme de régulation et quant aux risques qu’ils font peser sur la société dans leur développement. 

Mais plus que cette analyse de l’adoption plus ou moins avancée de ces différentes familles de technologies de calcul, il est intéressant de comprendre la manière dont au sein du discours critique est exprimée la temporalité. Des travaux portant sur les formes argumentatives en sociologie des controverses nous invitent à nous intéresser à la manière dont sont déployées les échelles temporelles et les régimes d’énonciation du futur qui leur sont associés (Chateauraynaud, 2013, 2014 ; Chateauraynaud, Debaz, 2019). Les épreuves de cohérence et de crédibilité dans les controverses nécessitent de définir des échelles temporelles qui vont venir modifier les jugements mais aussi les logiques d’action qui y vont y être associées. C’est en mobilisant des marqueurs temporels qui articulent des références au passé et une projection à plus ou moins long terme dans le temps que les acteurs sont en mesure de constituer des prises sur le futur qui vont venir moduler le type d’action à entreprendre et l’urgence à agir pour pour faire face à une situation. 

A partir de notre corpus, nous avons extrait 500 entités nommées qui sont des marqueurs temporels présents au sein des articles  et de la même manière que pour les verbes, nous avons calculé de manière comparative leur score tf-idf sur l’ensemble des articles constituant les deux sous-ensembles intitulés “Robots” et "Algorithmes". La liste des entités extraite a été filtrer manuellement afin de ne conserver que les marqueurs temporels interprétables en dehors de leur contexte d’énonciation . L’analyse comparative de la distribution entre les deux sous-ensembles des scores tf-idf des marqueurs temporels laisse apparaître deux régimes distincts de référence au temps au sein des articles. 
Du côté des articles associés au sous-ensemble “Robots” les marqueurs de temps relèvent d’une temporalité sur le long terme, qu’ils fassent référence au passé ou au futur. Ainsi la grande majorité des marqueurs se structurent autour d’expressions sur le futur qui mobilisent la figure the next associés à des temporalités qui se comptent souvent en dizaines d’années ou centaines d’années (the next 10 years, the next 30 years, the next 100 years, the next 1,000 years). D’autre part, les énoncés qui ont les plus importants scores dans cet espace ont comme particularité le plus souvent de ne pas définir précisément les échéances auxquelles ils renvoient (the next decades, coming decades, next century, this century). D’autres marqueurs également présents dans ce sous ensemble ne font pas référence au futur mais au passé et ils se caractérisent par le fait de référer également à une projection lointaine dans le temps passé (30 years ago, 150 years ago, the last 20 years, the past 25 years, the past 15 years). Les entités dans ce sous-ensembles ont donc comme particularité de majoritairement exprimer un futur lointain et souvent peu précis. Par ailleurs, lorsque les entités font référence au passé, elles sont également projetées dans une temporalité lointaine.
Au sein du sous-ensemble d’articles associés aux "Algorithmes" les marqueurs temporels extraits ayant les scores tf-idf les plus hauts se distinguent des premiers car ils renvoient majoritairement au présent (this day, these days, that year), à un passé plus proche souvent exprimé en jour, semaine ou mois (recent days, just last week, a few weeks ago, just a month, six months ago, the end of last year), mais également à un futur très proche en comparaison du premier sous-ensemble (the next day, the next few weeks, the coming weeks, the coming months, the following two years). 



## Méthode : Extraction des verbes et marqueurs de temps 


Extraction des verbes et calcul des TF-IDF sur le graphe 
L’analyse des verbes de troubles a été réalisée, à partir du logiciel Cortext, en effectuant une première extraction de 1000 verbes sur le texte complet des articles critiques du corpus en employant la méthode “pigeon holes”. 
La liste de verbes ainsi produite a d’abord été manuellement annotée afin d’extraire une sous liste de 431 verbes pouvant être interprétés comme des problèmes, des difficultés ou des troubles. En effectuant plusieurs itérations de visualisation matricielle des scores de tf-idf pour chacun des verbes sur l’ensemble des articles associés aux 17 clusters principaux (supérieur à 1% d’articles du corpus) via l’outil clustergrammer  une liste plus restreinte de 66 verbes a été sélectionnée présentant une plus forte saillance dans la matrice et étant plus explicitement interprétables comme troubles.
Le calcul final du score tf-idf s'effectue en produisant une matrice du nombre d'occurrences brutes des verbes (en ligne) par documents dans chacun des 23 clusters (en colonne). On calcule la somme des occurrences suivant les deux grands sous ensembles définis en suivant la topologie sur l’axe de l’incarnation, produisant deux ensembles comparables en volume d’articles (Robots : 52% articles - 9 clusters > 1% - 1790 termes ; Algorithmes : 48% articles - 8 clusters > 1% - 1201 termes).
La matrice finale compte 66 verbes en ligne et deux colonnes correspondant aux deux sous-ensembles algorithmes et robots. Le calcul du score tf-idf est obtenu à partir du module TfidfTransformer  en conservant les options par défaut (intégrant la fonction smooth_idf=True, la constante "1" est ajoutée au numérateur et au dénominateur de l'idf comme si l'on voyait un document supplémentaire contenant chaque terme de la collection exactement une fois, ce qui évite les divisions par zéro : idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1.

Extraction des entités nommées “Date” et calcul des TF-IDF sur le graphe 
En suivant la même procédure que pour le calcul des scores tf-idf sur les verbes, un travail de comparaison d’entités nommées “Date” a été réalisé. Afin de lister ces marqueurs de temps, une première extraction de 500 entités nommées via le modèle Spacy  effectuée sur Cortext  a été effectuée, puis un nettoyage de cette liste afin de conserver les entités les plus interprétables permettant de qualifier une dimension temporelle sans ambiguïté. On était supprimées les entités produisant des ambiguïtés et  moins interprétables comme les dates spécifique ou chiffrée, les durées (ex: several years, winter), les fréquences (ex : everyday, weekly), les périodes (the late 1980s) événement spécifique (ex : christmas). Pour cette liste de 112 entités “Date” un score de tf-df a été calculé en suivant la même procédure que pour les entités, soit une séparation du corpus d’articles en deux grand ensemble équivalent suivant la topologie du graphe telle que décrite précédemment et un calcul du score tf-idf pour chaque entité à partir du module TfidfTransformer.


  https://maayanlab.cloud/clustergrammer/
  https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html 
  https://spacy.io/models
  https://www.cortext.net

  Extraction de 1000 verbes par la méthode pigeon_holes au niveau de la phrase au sein de chaque document via le logiciel Cortext. Sélection manuelle des verbes les plus interprétables parmi la liste initiale.

  Calcul de la  fréquence d’apparition et de la spécificité d’usage d’un terme au sein du corpus


Entités nommées intitulé “Date” dans le modèle d’extraction de terme de Spacy réalisée via le logiciel Cortext

  On était supprimées les entités produisant des ambiguïtés et  moins interprétables hors de leur contexte d’énonciation comme les dates spécifiques ou chiffrées, les durées (ex: several years, winter), les fréquences (ex : everyday, weekly), les périodes (the late 1980s) événement spécifique (ex : christmas). 
