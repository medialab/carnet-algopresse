
## Quels sont les thèmes sur lesquels porte la critique ? 

**Carte sémantique des thématiques des articles “critiques”**

Le réseau sémantique obtenu à partir des 2 091 articles annotés comme critiques repose sur une extraction de termes les plus représentés au sein des articles . Il est constitué de 2 991 termes (ou suite de termes) reliés entre eux par 54 062 liens de cooccurrences. La spatialisation  est basée sur une variante de l’algorithme de spatialisation Fruchterman Reingold, incluant le poids des cooccurrences entre les termes du réseau ; la position est optimisée par leur appartenance aux clusters détectés automatiquement par l’algorithme de Louvain. La couleur des nœuds est relative à chacun des clusters ainsi détectés et leur taille est relative à la somme des cooccurrences. 

À partir des termes les plus représentés au sein de chacun des clusters on peut interpréter et nommer les thèmes qui structurent l’espace sémantique de ce corpus d’articles critiques de l’IA et des algorithmes. La cartographie est constituée de 23 clusters thématiques de tailles variées qui représentent des types de calculateurs ou des domaines d’application différents. Pour chaque article, en fonction des termes mobilisés, il lui est assigné un seul et unique cluster. De la même manière chaque terme est associé à un unique cluster même s’il peut entretenir des liens de cooccurrence avec d’autres termes appartenant à des clusters différents. Une première lecture du réseau consiste à décrire les thèmes les plus présents au sein du corpus en nombre d’articles et d’en proposer une illustration succincte à partir d'exemples de titres prototypiques qui leurs sont associés.

Le deux plus importants clusters du graphe en nombre d’articles forment deux pôles opposés. 

**ZOOM ou filtre cluster Carte sémantique des thématiques des articles “critiques” x 2**

 - Le plus important nommé “Web Algorithms", représentant 22% des articles du corpus critique, comporte des articles qui traitent des troubles produits par les algorithmes du web tels que par exemple les techniques de classement du newsfeed de Facebook (*Facebook accused of censoring conservatives, report says* - The Guardian - 10/05/16), les recommandations des vidéos sur Youtube (*YouTube, the Great Radicalizer* - The New York Times - 11/03/18) ou encore des moteurs de recherche comme Google (*Google results claim that the Holocaust didn't happen, and company won't change it* - Independent Online - 15/12/16). 
 - À l'extrémité opposée du graphe, on trouve le second plus important cluster nommé “Future of AI” qui représente 18% du corpus d’articles, évoquant les risques de l’émergence d’intelligences artificielles et de machines autonomes imitant ou surpassant les capacités humaines (*AI will create 'useless class' of human, predicts bestselling historian* - The Guardian - 20/05/16) ou menaçant l’humanité d'extinction (*End of Humanity ? Artificial Intelligence could destroy us ‘within decades’ warns expert* - express.co.uk - 15/04/16).

**ZOOM ou filtre cluster Carte sémantique des thématiques des articles “critiques” x 3**

Parmi les plus importants clusters on trouve trois autres thèmes largement représentés dans le corpus. 
- Le cluster “Job automation” (14% des articles) contient des articles alertant sur les risques de mutation du marché de l’emploi face à la robotisation et au déploiement de l’IA dans le monde du travail (*Robots and AI are threatening close to a third of UK jobs, study reveals* - Independent Online - 24/03/17). 
- Le cluster “Killer robots” (11% des articles) est constitué d’articles sur les risques du déploiement de l’IA et de machines autonomes dans le cadre de conflits armés (*Top scientists call for ban on killer robots to prevent apocalyptic war* - dailystar.co.uk - 20/08/17). 
- Enfin, le cluster “Facial recognition” qui représente 10% des articles du corpus porte sur différents développements des technologies de reconnaissance faciale dans l’espace public, dans des logiciels ou sur les plateformes du Web (*China is now using facial recognition cameras to monitor Uighur Muslims across the country, report claims* - Mail Online - 15/04/19). 

L’ensemble de ces 5 plus grands clusters thématiques domine largement l’espace médiatique car ces derniers ne constituent pas moins de 75,6% du total des articles du corpus critique (1581 articles) et représentent sur le graphe 46,4% du réseau de termes extraits (1389 termes).

**ZOOM ou filtre cluster Carte sémantique des thématiques des articles “critiques” x 9**

Un second ensemble, bien que très hétérogène du point de vue des thématiques déployées et de leur position au sein du graphe, est constitué de 9 clusters qui représentent respectivement entre 1% et 4% du nombre d’articles du corpus. L’ensemble de ces thèmes représente 21,6% des articles du corpus (452 articles) et 38 % des termes du graphe (1136 termes). Dans ce sous ensemble se trouvent les clusters :
- “Voice Assistant” : *Google's Nest microphone intensifies privacy concerns* -  _The Washington Post_ - 25/02/19
- “Autonomous Cars” : *Self-driving cars will need to be programmed to kill their owners, academics warn, and people will have to choose who will die* - Independent Online - 27/10/15
- “Sex Robots” : *Sex robots could lead to population crisis as men opt for virtual girlfriends* - Mirror.co.uk - 27/01/19
- “Health_Algorithms” : *Racial bias in a medical algorithm favors white patients over sicker black patients* - _The Washington Post_  - 25/10/19
- “Deepfake” : *You thought fake news was bad? Deep fakes are where truth goes to die* -  _The Guardian_  - 2/11/18
- “Predictive Algorithms” : *Criminal justice software algorithm used across the US is biased against black inmates, study finds* - Independent Online - 27/06/16
- “Chatbot” : *Microsoft 'deeply sorry' after AI becomes 'Hitler-loving sex robot'* - The Telegraph Online - 26/03/16
- “Game and Education” : *Korean Go master quits the game because AI 'cannot be defeated* - CNN Wire - 28/11/19
- “Profiling Algorthms” : *Artificial intelligence can identify 'gay faces' from a picture, study claims* - Independent Online - 08/09/17

**ZOOM ou filtre cluster Carte sémantique des thématiques des articles “critiques” x 9**
Enfin le graphe se compose de 9 autres clusters de taille très réduite, entre 0,8% et 0,1% des articles pour chaque cluster (58 articles au total). Les termes extraits de ces articles représentent pourtant 15,6% (466 termes au total) de la totalité des termes du graphe. Ces thématiques peuvent s’apparenter à des signaux faibles d’un discours critique sur les algorithmes et l’IA détectés par notre méthode d'extraction de termes mais pourtant sous représentés en volume d'articles. Ces clusters se centrent autour de thématiques très spécifiques, évoquant parfois des types de calculateurs mais le plus souvent des domaines d’application :
- “Robot-Advisers” : *Mortgage algorithms found to have racial bias* - The Washington Post - 15/11/18
- “DeepDream Nightmares” : *The AI 'nightmare machine': Spooky Google algorithm transforms famous sights into horror scenes* - Mail Online - 25/10/16
- “Deep Voice” : *Creepy AI can clone anyone's voice with just one minute of audio* - Mail Online - 25/04/17
- “Scientific Research” : *Facebook shuts down chatbot experiment after AIs spontaneously develop their own language* - London Evening Std Online - 01/08/17
- “Market and Prices” : *Artificial Intelligence - Beware Algorithms That Could Collude To Unfairly Raise Prices* - The Wall Street Journal - 02/04/19
- “Image Search” : *Three black teenagers': anger as Google image search shows police mugshots* - The Guardian - 10/06/16
- “Email” : *Google expands 'creepy' Gmail AI that can automatically reply to emails for you* - Mail Online - 31/08/18
- “Music” : *Why 'random' shuffle feels far from random* - Independent Online - 24/02/15
- “Consumer and Copyright” : *Apple is forced to change its App Store search algorithm after it emerged its own products were being ranked significantly higher* - Mail Online - 09/09/19

## Comment évolue l'agenda médiatique ? 

**Timeline clusters / nb articles 3 profils**

L’analyse de la distribution temporelle du nombre d’articles des dix plus importants clusters sur la période de 5 années que couvre le corpus critique laisse apparaître trois profils distincts. On observe une distribution assez stable sur la période de la répartition des articles des deux plus grands clusters structurants de la cartographie que sont les “Web Algortihms” et “Future of AI”. La distribution de ces deux plus grands clusters montre qu’il existe une production régulière d’articles critiques sur les troubles liés aux algorithmes du web et aux craintes relatives aux  développements futurs de l’intelligence artificielle et des robots. Ces thèmes concentrent le plus grand nombre d’articles et forment deux pôles sur lesquels s'établit de façon récurrente un discours critique. 
Un second profil de distribution concerne les clusters “Facial recognition” et “Deepfake” qui connaissent une hausse importante du volume d’articles publiés sur l’année 2019. Enfin le troisième profil de distribution montre une hausse du nombre d’articles qui se concentrent sur les années 2017 et 2018 et une baisse significative sur l’année 2019. Ce type de distribution concerne les clusters “Job Automation”, “Killer Robots”, “Autonomous Cars”, “Sex Robots”, “Voice Assistant”, “Predictive Algorithms”. 

**Timeline Termes related non critique clusters profils identique aux variation**

Il est plus difficile d'interpréter ces distributions irrégulières étant donné la méthode d’annotation du corpus utilisée, mais elles semblent montrer la manière dont la presse, en focalisant son attention sur certaines technologies plutôt que d’autres, constitue un agenda médiatique sur lequel se déploie également un discours critique. Afin de vérifier cette hypothèse d’une distribution concentrée sur des périodes spécifiques, focalisant l’attention médiatique sur certaines technologies, indépendamment de la production d’un discours critique, nous avons tenté d’observer les distributions de certains termes constitutifs de ces clusters au sein du corpus d'articles étiquetés comme non-critique. Ces distributions montrent une répartition similaire à celle observée pour les clusters du corpus critique. Ainsi les “deepkake” connaissent une fréquence d’apparition croissante au sein des articles non critiques entre 2018 et 2019. La même distribution est observable également pour le terme “facial recognition” qui croît progressivement jusqu’en 2019. L’ensemble des termes associés aux robots sexuels présents dans le corpus étiqueté comme non critique connaissent leur plus forte fréquence sur les années 2017 et 2018 avant de diminuer en 2019, on observe également le même phénomène de concentration de la fréquence d’apparition des termes relatifs aux voitures autonomes sur les années 2017 et 2018, ou encore pour les termes relatifs aux assistants vocaux dont la plus forte distribution se concentre sur la même période.

---
**Méthode : Extraction et visualisation du graphe de termes**

**Extraction de termes dans le corpus :**
L’analyse sémantique du corpus critique a été effectuée à partir du logiciel Cortext en effectuant une extraction de termes sur le texte complet des articles (titre, lead paragraph et texte de l'article) puis un nettoyage des listes de termes extraites suppression de stopwords (balises des fichiers vidéo ou élément de timecode non nettoyés dans factiva). 
L’extraction de termes a été réalisée à partir de la méthode “pigeon holes” (favorisant la spécificité des termes et leur occurrence par document ) au niveau des phrases. 6000 noms incluant des monogrammes ainsi que les bigrammes et trigrammes. S'il peut paraitre étrange que certains termes assez proche ont été conservé, par exemple toutes les variantes de facial recognition, nous avons fait le choix de conserver cette hétérogénéité afin de rendre compte de diversité des manières de définir les agents calculateurs.

**Production du réseau de cooccurrence et clustering :**
L’analyse du corpus a été réalisée à partir d’un graphe de 2 991 termes reliés entre eux par 54 062 liens de cooccurrences. La spatialisation produite par le logiciel Cortext - https://www.cortext.net, puis visualisée dans le logiciel Gephi - https://gephi.org, est basée sur une variante de l’algorithme de spatialisation Fruchterman Reingold dont la position des nœuds est optimisée par leur appartenance aux clusters détectés automatiquement par l’algorithme de Louvain. La couleur des noeuds est relative à chacun des clusters ainsi détectés et leur taille est relative à la somme des occurrences du terme au sein du corpus. Chaque article du corpus est ainsi associé à un unique cluster d’appartenance en fonction des termes qu’il contient. Les clusters ont été interprétés qualitativement et nommés en fonction de leur cohérence thématique, qualifiable à partir des termes les plus fréquents au sein de chacun des clusters.

