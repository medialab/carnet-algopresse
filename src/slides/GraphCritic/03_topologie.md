
## Qu'est-ce que la topologie du réseau nous apprend ? 

La dispersion des clusters de termes dans l’espace topologique laisse apparaître une opposition entre deux principaux types de calculateurs qui apparaît lorsque l’on trace un axe horizontal allant de droite à gauche. On peut interpréter cet axe comme un processus d’autonomisation progressive de l’IA par rapport à son environnement. On observe ainsi un déplacement entre des articles mettant en scène des techniques de calcul algorithmique incorporées dans l'environnement de l’utilisateur pour guider, orienter ou calculer ses comportements, vers des articles qui se caractérise par la personnification de l’IA dans une entité incarnée et autonome à l’égard des humains.  La première zone à droite concerne exclusivement des algorithmes, qu’ils s'agissent des algorithmes du Web comme le fil d’actualité de Facebook, la section trending topic de Twitter, les algorithmes de recherche d’images et de sites web de Google. La plupart de ces agents calculateurs sont définis dans les articles comme des algorithmes et constituent les couches techniques de services largement déployés dans nos environnements numériques quotidiens. Si la majorité de ces dispositifs sont ancrés dans les usages quotidiens, d’autres représentent des technologies plus émergentes qui font l'objet de développements et d'expérimentations plus localisées et plus régulées telles les algorithmes de police ou de justice prédictive, de détection des images dans les systèmes de reconnaissance faciale ou les deepfakes.
Dans la partie la plus à gauche, à l’opposé du graphe, les clusters se concentrent autour d’agents calculateurs qui sont davantage incarnés sous forme de machines ou de robots. Les entités qui peuplent cette zone sont personnifiées dans des dispositifs physiques séparés de nos équipements numériques habituels que sont nos ordinateurs et nos smartphones. Ces dispositifs, en plus d’être incarnés physiquement sont équipés d’une capacité d’agir  autonome via de systèmes de calcul basés sur l’IA. En simulant à la fois le corps et les capacités cognitives des humains ils sont en mesure de produire certaines actions sans intervention humaine dans différents domaines telles que le transport avec les voitures autonomes, la défense avec les “robots tueurs” et les drones, le travail avec l'automatisation des tâches professionnelles ou encore les relations physiques avec les robots sexuels.
Entre ces deux pôles existe une zone intermédiaire plus difficilement identifiable, constituée de dispositifs à mi-chemin entre les machines autonomes et les algorithmes de nos environnements numériques quotidiens. Parmi les agents calculateurs présents dans cet espace on retrouve par exemple les assistants vocaux pouvant être embarqués dans nos smartphone ou dans des dispositifs du type enceinte connectées, les chatbots du Web, les robo-advisors qui sont les algorithmes effectuant des opérations dans le domaine de la finance ou encore des technologies de deep learning comme le dispositif Deep Dream de Google. Ces technologies bien qu’assez accessibles au grand public sont souvent encore émergentes. Elles sont en capacité de gérer un certain nombre de tâches parfois basiques de manière autonome mais ne sont pas toujours incarnées dans des dispositifs physiques, elles sont encore le plus souvent implémentées et accessibles via nos ordinateurs et smartphones. Un autre exemple de cette zone intermédiaire est la présence du cluster nommé “Health Algorithms" qui regroupe un ensemble d’articles portant à la fois sur des applications de détection automatisée des cycles menstruels dans des applications mobiles grand public mais également l’utilisation de méthode de machine learning innovantes dans le domaine de la radiologie médicale.

La séparation entre les mondes des robots et des algorithmes que nous venons de faire apparaître dans la topologie des termes issus des articles de presse permet maintenant d’interroger la manière dont les thématiques distribuées sur l’axe de l’autonomisation de l’IA font apparaître deux registres discursifs distincts. La tendance du graphe à séparer des dispositifs de calcul aux propriétés différenciées, nous amène à explorer ces dimensions de manière plus approfondie. Afin de réaliser une analyse comparative entre les deux pôles qui se dégagent de l’analyse topologique, le choix a été fait de découper le réseau en deux zones sur l’axe de l'autonomisation de l’IA, produisant deux sous-ensembles comparables en terme de volume d’articles, de clusters et de termes. Ainsi, l’espace intitulé “robots” compte 52% des articles du corpus, 9 clusters principaux (de taille supérieure à 1%) et 1790 termes. L’espace intitulé “algorithmes” représente quant à lui 48% articles, 8 clusters principaux et 1201 termes. Par une approche comparative, ce découpage en deux sous-ensembles équivalents permet d’explorer les différents attributs qui peuplent ces deux espaces sémantiques.

Les méthodes de traitement automatique du langage permettent une analyse des éléments des discours critiques, à partir des termes saillants extraits au sein des articles, peuplant ces deux espaces sémantiques. Pour mettre en évidence les caractéristiques de ces deux régimes de critique, nous avons entrepris d’identifier systématiquement la manière dont sont désignées les entités techniques, la société qui les abrite et la façon dont les premiers ont des effets sur la seconde. Tous ces discours critiques cherchent à qualifier la manière dont des Agents produisent des Victimes en exerçant un type particulier d’Opération ; ces dernières sont constitutives d’un ensemble de troubles révélant autant de nouveaux défis, ou d’Enjeux, produits par le déploiement des techniques d’IA dans nos sociétés  (Cardon, Crépel, 2019).

Afin de différencier ces entités au sein du graphe, la plupart des termes, ne souffrants pas trop d'ambiguïté (66% des termes du graphe), ont été annotés manuellement en dix catégories distinctes . Parmi ces catégories, notre analyse consiste à comparer trois d’entre elles qui apparaissent particulièrement pertinentes pour différencier les deux espaces. La catégorie Agent “Technical” renvoie à ce que nous avons désigné comme agents calculateurs, elle concerne toutes les termes relatifs aux entités techniques tels que les algorithmes, les machines, les fonctionnalités ou services techniques, les terminaux mais également les produits ou services issus le plus souvent de startup qui sont parfois difficiles à différencier de l'entité économique qui les a produit. La seconde catégorie relative aux agents humains, nommée “People”, concerne tous les termes désignant des personnes ou groupes de personnes non nommées (à la différence des catégories “Person” pour les noms propres et “Institutions” pour les groupes ou structures ayant une existence juridique). Enfin la troisième catégorie, nommée “Issues”, permet d’identifier les termes qui désignent des enjeux, des difficultés ou des problèmes extraits au sein des articles. 


## Qui sont les agents calculateurs ? 

**Visualisation Technical Tag**

La décomposition des qualifications des Agents de l’IA fait apparaître des entités techniques aux propriétés très différentes. Ce qui caractérise les Agents de la zone “robots” de notre cartographie est le très haut degré d’intelligence et d’autonomie des IA, ainsi que leur capacité à être incarné sous la forme de machines. Le terme de robot domine cet espace et que ce soit pour la conduite automobile, le sexe, la guerre ou la production industrielle, ces Agents sont dotés de capacité d’initiatives autonomes. Les caractéristiques qui leurs sont données contribuent à détacher leur capacité de choisir, de décider et d’agir du système socio-technique qui les a produits ou de l’environnement dans lequel ils se déploient. En revanche, les agents de la zone “algorithmes” de notre cartographie n’ont pas cette autonomie et sont plutôt définies comme des parties ou des éléments de systèmes sociotechniques distribués dans des environnements numériques.

Si l’on compare les termes les plus fréquents catégorisés en tant qu’entité technique, on observe que dans l’espace “Robots” les calculateurs renvoient le plus souvent à des dispositifs incarnés tels que les robots, les machines, les ordinateurs, les voitures, les armes, les drones, les weapons, les dolls. D’autres entités techniques se distinguent car elles renvoient à une définition très abstraite et générique des calculateurs qui sont désignés en tant que system, artificial intelligence ou encore comme automation ou model. Dans l’espace sémantique intitulé “Algorithmes” les entités techniques, même sous des dénominations abstraites, ne constituent pas des objets autonomes (algorithm, devices, program, bot ou phone). La majorité des termes se distingue par le fait qu’elle relève de technologies beaucoup plus spécifiques, renvoyant le plus souvent à des dispositifs technologiques précis tels que facial recognition, deepfake, social network, chatbot, criminal justice algortihm et de manière encore plus spécifique à des fonctionnalités de certains services embarqués dans nos terminaux mobiles ou sur le web, parfois associés à des marques, tels que Siri, Search engine, Trending topics, Google assistant, Iphone, recommendation algorithm, Facebook messenger, Google images, image search. Ces qualifications n’isolent pas les IA mais les incorporent dans un environnement sociotechnique dans lequel le calcul joue un rôle de plus en plus intense pour assister, trouver de l’information, guider ou prévenir un comportement. 

## Qui sont les agents humains ? 

**Visualisation People Tag**

La catégorie “People” à partir de laquelle ont été annotés dans les termes désignant des agents humains, personnes ou groupes de personnes non nommées ou n’ayant pas d’existence institutionnelle, permet d’observer la manière dont est composé le monde social dans lequel les IA ont été introduites. Elle fait apparaître une autre différence entre les deux espaces sémantiques. Du côté de l’espace “Robots” on observe parmi les termes les plus fréquents une forte présence de références à l’humanité, telles que humans, humankind, human civilisation, human driver, human supervisor. À la lecture du contenu de certains articles associés à cet espace, on constate que face aux agents calculateurs incarnés par des machines, tels que décrits précédemment, la notion d’humanité est en fait une expression très générique de la société humaine tout entière sur laquelle ces agents font peser une menace. D’autres termes assez génériques sont également présents dans cet espace mais relèvent d’une définition plus centrée sur des domaines dans lesquels les technologies robotiques sont amenées à se déployer, tels que la finance, le marché du travail, la défense et les transports. On retrouve ainsi des termes tels que workers, customers, employees, drivers, retailers, soldiers, passengers, brokers, traders, farmers. L’espace associé aux “Algorithmes” est quant à lui peuplé de termes beaucoup moins génériques que dans l’espace sémantique des “Robots”. Les agents humains sont ici désignés de manière beaucoup plus précise et font référence à des personnes mieux identifiées. On retrouve ainsi, parmi les termes fréquents, des entités faisant référence aux plateformes numériques users, accounts, Facebook users, Youtube users. Les termes qui désignent ces agents permettent dans la grande majorité de les qualifier en fonction de propriétés comme l’âge (children, child, kids, parents), le genre (women, men) l’appartenance éthnique (black people, black patients, african-americans), l’orientation politique (white supremacists, black defendants, illuminati) ou sexuelle (gays, lesbian, trans people).

L’analyse topologique des clusters faisant apparaître une opposition entre les machines ou intelligences autonomes et les environnements numériques algorithmiques, est renforcée par une analyse plus spécifique des termes les plus fréquents qui peuplent ces deux espaces. En effet, on observe dans l’espace sémantique intitulé “Robots” une forme d'abstraction et d’incarnation des agents techniques et une généricité dans la manière de désigner les agents humains qui apparaissent comme les victimes des troubles potentiels tels qu'ils sont dénoncés dans les articles critiques. À l’inverse, dans l’espace lié aux “Algorithmes”, les agents techniques sont davantage spécifiés et renvoient le plus souvent à des services ou des fonctionnalités techniques très précises qui sont mis en cause dans les articles. Les agents humains associés à ces entités techniques algorithmiques ne réfèrent pas à des catégories génériques comme l’humanité toute entière mais sont qualifiés par une variété d’attributs qui permettent de les identifier de manière beaucoup plus précise.  

## Quels sont les troubles produits par ces agents calculateurs ? 

**Visualisation Issue Tag**

La catégorie intitulée “Issues” permet une lecture comparée des termes relatifs aux troubles et aux enjeux qui sont associés aux agents techniques sur lesquels porte la critique. Du côté de l'espace sémantique “Robots”, c’est l’affrontement entre les humains et les IA qui est constamment appelé comme enjeu. On observe la présence de termes tels que attack, safety, arms race, Cold war, human extinction, extinction, natural disasters, AI-powered horror, mass extinction, physical damage, qui renvoient le plus souvent au registre de la guerre ou de destruction à l’échelle planétaire, faisant peser un risque existentiel sur l’avenir de l’humanité. Ces menaces font émerger des enjeux de contrôle de ces technologies autonomes, tels que ban, petition, human oversight, lack of accountability, superintelligence control problem, control problem. D’autres termes relèvent de troubles assez visibles dans cet espace sémantique associés au remplacement, au dépassement et à une perte de contrôle de l’homme par les machines, notamment dans le domaine de l’économie, avec des termes tels que job losses, surge pricing, pay gap.
Les termes relatifs aux troubles et enjeux constitutifs du sous-ensemble nommé "Algorithmes" laissent apparaître d’autres formes de discours de critique davantage imprégnées de références juridiques et légales. En effet, on trouve dans cette partie du graphe parmi les termes fréquents un champ sémantique constitué de références juridiques tels que crime, law enforcement, Human Rights, lawsuit, Civil Liberties, prejudice, fraud, public interest. Les troubles produits par les agents techniques dénoncés au sein des articles associés à cet espace concernent les discriminations (bias, biases, discrimination, antisemitic, race or gender, fair use, risk score, liberal bias), les enjeux de privacy (privacy, surveillance, Big Brother, privacy issues), les difficultés de filtrage ou d’exposition à de contenus innapropriés (violence, inappropriate content, nudity, age restriction, violent crime) et frauduleux (fake news, misinformaton, conspiracy theories, revenge porn, filter bubble), ou encore de censure et de liberté d’expression (free expression)



---
## Méthode : Division du corpus en suivant la topologie et tagging des entités

**Division du corpus en suivant la topologie :**
Pour faciliter une analyse comparative entre l'espace sémantique intérprété comme lié aux "robots" et l'espace lié aux "algorithmes" chaque cluster a été associé à l'une ou l'autre de ces catégories. Les deux sous-ensembles sont comparables en terme de volume d’articles, de clusters et de termes. 
L'espace intitulé “robots” compte  : 
- 9 clusters principaux (de taille supérieure à 1% du corpus d'articles)
- 52% des articles du corpus (chaque article étant associé à un unique cluster)
- 1790 termes au sein du réseau (chaque terme étant associé à un unique cluster). 
L’espace intitulé “algorithmes” compte 
- 8 clusters principaux (de taille supérieure à 1% du corpus d'articles)
- 48% articles (chaque article étant associé à un unique cluster)
- 1201 termes au sein du réseau (chaque terme étant associé à un unique cluster).

**Tagging des entités du réseau :**

Pour chacun des 2991 termes du réseau une catégorisation manuelle a été réalisée à pour différencier le type d’entités, de sorte que 66% des termes du réseaux ont été catégorisés à partir de 10 catégories distinctes : 
- Technical (15%) : Calculateur, Machine, Fonctionnalité, Devices, Service Technique, Dispositifs techniques de startup difficiles à différencier de l'entité économique
- Company (5%) : Entreprises, Start-up, Domaine d'entreprise
- Fiction (1%): personnages, films, jeux vidéo
- Person (6%) : Personnalités politique, médiatique, recherche, noms propres
- People (8%) :  personne ou groupe de personnes non nommée
- Institution (4%) : Agence gouvernementale, ONG, Association, Université, Textes juridiques
- Locality (1%) : Lieux
- Data_inout (10%) : Données, traces	
- Topic (10%) : Domaine, Thèmes
- Issues (7%) :  Enjeux et problèmes

Une 11ème catégorie rassemble les termes difficilement interprétables et non catégorisables
- NC terms (34%) : Termes non classés car trop ambigus ou non pertinents 

